# PDF-Based Question Answering System using RAG (Retrieval-Augmented Generation)

A full-stack Retrieval-Augmented Generation (RAG) system that allows users to upload a PDF document and ask natural language questions based on its content.

This project combines:

- ğŸ§  FastAPI backend for PDF processing, chunking, embeddings, and LLM integration
- âš›ï¸ React (Vite) frontend for an interactive and modern user interface
- ğŸ’¬ Gemini LLM for natural language answer generation

## ğŸš€ Features

- ğŸ“„ Upload any PDF document
- ğŸ” Semantic chunking using embeddings (SentenceTransformer)
- ğŸ“š Vector similarity search with FAISS
- ğŸ§  Gemini LLM generates accurate, context-based answers
- âš¡ FastAPI backend for efficient processing
- ğŸ’… React + TailwindCSS frontend
- ğŸ”’ CORS-enabled API connection between frontend and backend

## ğŸ§± System Architecture

```
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Frontend  â”‚ (React + Vite)
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
             â”‚  API calls
      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
      â”‚  FastAPI   â”‚  (Python Backend)
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚  PDF Uploadâ”‚
      â”‚  Text Extractionâ”‚
      â”‚  Chunking       â”‚
      â”‚  Embedding      â”‚
      â”‚  FAISS Indexâ”‚
      â”‚  Gemini LLMâ”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
             â”‚
        â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
        â”‚  Client â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

# ğŸ“‚ RAG-QA Project

## ğŸ“– Table of Contents
- [Project Structure](#project-structure)
- [âš™ï¸ Backend Setup (FastAPI)](#%EF%B8%8F-backend-setup-fastapi)
  - [1ï¸âƒ£ Move into Backend Directory](#1ï¸âƒ£-move-into-backend-directory)
  - [2ï¸âƒ£ Create Virtual Environment](#2ï¸âƒ£-create-virtual-environment)
  - [Activate Virtual Environment](#activate-virtual-environment)
  - [3ï¸âƒ£ Install Dependencies](#3ï¸âƒ£-install-dependencies)
  - [4ï¸âƒ£ Create `.env` File](#4ï¸âƒ£-create-env-file)
  - [5ï¸âƒ£ Run Backend Server](#5ï¸âƒ£-run-backend-server)
- [âš›ï¸ Frontend Setup (React + Vite)](#%EF%B8%8F-frontend-setup-react--vite)
  - [1ï¸âƒ£ Move into Frontend Directory](#1ï¸âƒ£-move-into-frontend-directory)
  - [2ï¸âƒ£ Install Dependencies](#2ï¸âƒ£-install-dependencies)
  - [3ï¸âƒ£ Start Development Server](#3ï¸âƒ£-start-development-server)
- [ğŸ”— Connecting Frontend and Backend](#%EF%B8%8F-connecting-frontend-and-backend)
- [ğŸ§© API Endpoints](#%EF%B8%8F-api-endpoints)
  - [Example: Upload PDF](#example-upload-pdf)
  - [Example: Ask Question](#example-ask-question)
- [ğŸ§  How It Works](#%EF%B8%8F-how-it-works)
  - [Step 1: Upload PDF](#step-1-upload-pdf)
  - [Step 2: Ask a Question](#step-2-ask-a-question)
- [ğŸ§© Chunking Technique](#%EF%B8%8F-chunking-technique)
- [ğŸ§° Dependencies](#%EF%B8%8F-dependencies)
  - [Backend](#backend)
  - [Frontend](#frontend)
- [âš ï¸ Common Errors](#%EF%B8%8F-common-errors)
- [ğŸ§© Future Improvements](#%EF%B8%8F-future-improvements)
- [ğŸ“œ License](#%EF%B8%8F-license)
- [ğŸ‘¨â€ğŸ’» Author](#%EF%B8%8F-author)

## Project Structure

```
RAG-QA/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPI entry point
â”‚   â”‚   â”œâ”€â”€ rag.py              # Core RAG system (retrieval + LLM)
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py    # Extracts text from PDFs
â”‚   â”‚   â”œâ”€â”€ models.py           # Pydantic models
â”‚   â”‚   â””â”€â”€ utils.py            # Chunking + helpers
â”‚   â”‚
â”‚   â”œâ”€â”€ uploads/                # Uploaded PDFs
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env                    # GEMINI_API_KEY here
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ FileUpload.jsx
    â”‚   â”‚   â”œâ”€â”€ ChatBox.jsx
    â”‚   â”‚   â””â”€â”€ Header.jsx
    â”‚   â”œâ”€â”€ App.jsx
    â”‚   â”œâ”€â”€ main.jsx
    â”‚   â””â”€â”€ index.css
    â”œâ”€â”€ package.json
    â””â”€â”€ vite.config.js
```

---

## âš™ï¸ Backend Setup (FastAPI)

### 1ï¸âƒ£ Move into Backend Directory
```bash
cd backend
```

### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
```

#### Activate Virtual Environment
```bash
venv\Scripts\activate      # On Windows
source venv/bin/activate   # On Mac/Linux
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Create `.env` File
```env
GEMINI_API_KEY=your_api_key_here
```

### 5ï¸âƒ£ Run Backend Server
```bash
uvicorn app.main:app --reload
```
âœ… Runs at â†’ http://127.0.0.1:8000  
Swagger Docs â†’ http://127.0.0.1:8000/docs

---

## âš›ï¸ Frontend Setup (React + Vite)

### 1ï¸âƒ£ Move into Frontend Directory
```bash
cd frontend
```

### 2ï¸âƒ£ Install Dependencies
```bash
npm install
```

### 3ï¸âƒ£ Start Development Server
```bash
npm run dev
```
âœ… Runs at â†’ http://localhost:5173

---

## ğŸ”— Connecting Frontend and Backend

Make sure the backend is running on port `8000` and the frontend on `5173`.  

CORS in `main.py`:
```python
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

---

## ğŸ§© API Endpoints

| Method | Endpoint | Description |
|--------|---------|-------------|
| POST   | /upload | Uploads a PDF and indexes its content |
| POST   | /ask    | Sends a user query and retrieves answer |

### Example: Upload PDF
```bash
curl -X POST "http://127.0.0.1:8000/upload" \
     -F "file=@sample.pdf"
```

### Example: Ask Question
```bash
curl -X POST "http://127.0.0.1:8000/ask" \
     -H "Content-Type: application/json" \
     -d '{"question": "What is the main topic of this document?"}'
```

---

## ğŸ§  How It Works

### Step 1: Upload PDF
- Extracts text with PyPDF
- Chunks it using semantic similarity (SentenceTransformers)
- Embeds with MiniLM model
- Stores in FAISS index

### Step 2: Ask a Question
- Converts the question to a vector
- Retrieves top-K similar chunks
- Combines them into a prompt
- Sends to Gemini LLM
- Returns natural, context-based answer

---

## ğŸ§© Chunking Technique

This project uses **Contextual Semantic Chunking** â€” sentences are grouped together based on cosine similarity between their embeddings.  

**Benefits:**  
- Maintain context  
- Avoid splitting mid-topic  
- Improve retrieval accuracy  

---

## ğŸ§° Dependencies

### Backend
- fastapi
- uvicorn
- pypdf
- langchain
- faiss-cpu
- requests
- python-multipart
- python-dotenv
- sentence-transformers
- google-generativeai

### Frontend
- react
- vite
- axios
- tailwindcss

---

## âš ï¸ Common Errors

| Error                  | Cause                            | Solution                             |
|------------------------|---------------------------------|-------------------------------------|
| Invalid Gemini API key  | Wrong key or missing .env       | Verify key in .env                   |
| Empty chunks            | PDF has no extractable text     | Ensure itâ€™s not scanned             |
| CORS error              | Backend not allowing frontend   | Add correct allow_origins           |
| 429 Too Many Requests   | Rate limit exceeded             | Wait and retry                       |

---

## ğŸ§© Future Improvements
- Support multiple document uploads
- Add persistent vector storage (ChromaDB / Qdrant)
- Integrate Streamlit dashboard
- Summarization & highlight features
- User authentication

---

## ğŸ“œ License
This project is released under the **MIT License** â€” free to use and modify.

---

## ğŸ‘¨â€ğŸ’» Author
**Haile Tassew**  
ğŸ“ Information Technology Student  
ğŸ’¡ Passionate about AI, Data Engineering & Intelligent Systems  
ğŸ“§ hailetassew4545@gmail.com  
